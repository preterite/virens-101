---
created: 2026-02-03
type: teaching-course-content
course: virens-101
component: f_assignments
track: content
identifier: ai-spec-test
paired-justification: [[ai-spec-test-reasons-v101]]
status: draft

# === OUTCOMES ALIGNMENT ===
outcomes-addressed: [specification, process-documentation, constraint-sequencing, metacognition]
outcomes-primary: specification

# === DEPENDENCY MANAGEMENT ===
sync-group: [fragment-model, time-structure]
depends-on: [arguable-claims, fragment-archive, eli-review-criteria, downs-rhetoric]
affects: [spec-document-assignment, constraint-audit]
uses-defs: [fragment-definition, block-duration]
last-sync-check: 
attention-flag: "Schedule integration: W5B4, W6B1, W6B2, W6B6"
tags: [teaching, virens-101, assignments, ai, specification, movement-2]
---

# The Spec Test: What Happens When You Tell a Machine What You Want?

> [!info] Course Content
> **Component**: Assignments
> **Track**: Content (what students encounter)
> **Schedule**: Week 5 Block 4 → Week 6 Blocks 1–2 (with optional reflection at Week 6 Block 6)

## Overview

This activity happens across two class sessions and one homework assignment. You will ask an AI to develop one of your claims into 500 words—twice. The first time, you give it almost nothing. The second time, you write a specification first. Then we compare results and talk about what the difference means for your writing.

You'll need your fragment archive open and a browser ready for both sessions.

---

## Before We Start: Choosing Your Claim

Browse your fragment archive—your literacy narrative, your source responses, your reactions to Meadows, Kirschenbaum, or other course readings—and identify one *arguable claim* you'd like to develop further.

Quick reminder of what makes a claim arguable:

- **Not an observation of fact.** "The library closes at midnight" isn't a claim—you can just look it up. "The library's midnight closing time hurts students who work evening shifts" is arguable.
- **Not purely personal taste.** "I don't like Meadows" isn't arguable in any productive way. "Meadows's leverage points framework underestimates how hard it is to identify where you are in a system" gives someone something to push back on.
- **Not trivial or vague.** "Writing is important" is true but gives nobody anything to work with. Be specific enough that someone could disagree with you in an interesting way.

You will use the **same claim for both sessions**, so pick one you actually care about developing.

---

## Session 1: Round 1 — No Spec (Week 5, Block 4)

### What You'll Do

1. Open a **private/incognito browser window** and navigate to [PRE-SPECIFIED-LLM-URL].
2. Paste your claim into the chat. Ask the AI to develop it into approximately 500 words of academic prose with appropriate evidence and at least one counterargument.
3. That's it. Don't coach it. Don't give it background. Don't tell it what you've been reading or what course this is for. Just the claim and the request.
4. When it responds, read what you got.

After everyone has output, you'll pair up with a neighbor and compare results:

- Read your partner's AI output.
- Quick gut check: thumbs up or thumbs down? Would this pass as a draft in this class?
- What's missing? What feels wrong? What, if anything, is useful?

---

### Fragment Prompt 1: AI Round 1 Output

**Context:** You just asked an AI to develop your claim into 500 words with no specification beyond the claim itself and basic requirements.

**Task:** Create a new fragment document titled with today's date and "AI-Round1-NoSpec." Paste the following into it: (1) the claim you submitted, (2) the full AI output, and (3) 2–3 sentences of your initial reaction—your gut response to what it produced.

**Standards:** The fragment must include all three elements. Do not edit the AI's output. Your reaction is a first impression; you'll do deeper work for homework.

**Guidance:** Save this in your M2 fragments folder. You'll need it next session.

---

## Homework: Dev Log Annotation (Due Before Week 6, Block 1)

**Context:** You have an AI-generated text that attempted to develop your claim without much guidance from you. Between now and next class, you'll look at it more carefully.

**Task:** Re-read the AI's output slowly. In your dev log, write an entry titled "AI Round 1 Annotation" that identifies **at least three specific places** where the output is unsatisfactory, and explains *why* for each.

**Standards:** Each annotation should (a) point to a specific passage or sentence in the AI output—quote it or describe its location—and (b) name what's wrong. Some possibilities: the evidence is fabricated or unverifiable, a counterargument is a straw man, the prose sounds authoritative but says nothing specific, a claim is made without any source, the argument structure doesn't actually follow from the evidence, the tone is wrong for the audience, key context is missing. Name the specific problem, not just "it's bad."

**Guidance:** As you annotate, think about this question: *What would you have needed to tell the AI to prevent each problem?* What do you know—about your sources, your argument, your audience, the standards for this kind of writing—that the AI didn't know because you didn't tell it? Hold that thought. We'll use it next class.

---

## Session 2: Round 2 — With a Spec (Week 6, Block 1)

### What You'll Do

1. Quick recall: last session you gave an AI your claim and almost nothing else. You annotated what went wrong. Today you'll try again—differently.
2. Take **5 minutes** to write a specification for the task. Before you open the AI, write down—on paper or in a document—what you want the AI to produce. Be as specific as you can. Think about:
   - What is this text *for*? Who's the audience?
   - What evidence should it draw on? What sources matter?
   - What counterarguments need to be addressed, and how?
   - What should the argument structure look like?
   - What tone, register, and level of formality are appropriate?
   - What should it *not* do?
3. Open a **new private/incognito browser window** (fresh session, no memory of Round 1) and navigate to [PRE-SPECIFIED-LLM-URL].
4. Paste your spec and your claim. Give the AI what you wrote.
5. Read what you get.

After everyone has output, pair up again:

- This time, **read your partner's spec first**, then read the AI's output.
- Where did the AI follow the spec? Where did it deviate?
- What did the spec fail to specify that would have mattered?
- Is the Round 2 output better than Round 1? In what ways? Where is it still unsatisfying?

---

### Fragment Prompt 2: AI Round 2 Output + Spec

**Context:** You wrote a specification for your claim and then asked an AI to develop it following that spec. You now have two versions of AI-assisted development of the same claim.

**Task:** Create a new fragment document titled with today's date and "AI-Round2-WithSpec." Paste the following into it: (1) your specification (the full text of what you wrote before opening the AI), (2) the AI's output, and (3) 2–3 sentences comparing this result to Round 1. What changed? What's better? What's still wrong?

**Standards:** The fragment must include all three elements: spec, output, and comparison. Do not edit the AI's output.

**Guidance:** Keep both Round 1 and Round 2 fragments in your archive. Either or both may contain material worth developing further—a phrase, an argument structure, a question the AI raised that you want to pursue. They're raw material now, like any other fragment. What you do with them is up to you.

---

## Discussion: What Just Happened? (Week 6, Block 2)

We'll spend this block talking about what the two rounds revealed. Some questions we'll work through together:

- What was different between Round 1 and Round 2? Where did the spec make the biggest difference?
- What problems did the spec *not* fix? What's still unsatisfying even with a good spec?
- If you had 20 minutes and needed 2,000 words of polished academic prose, and you were allowed to use AI however you wanted—how would you do it? Walk us through your process.
- Where else in this course have you already been working with specifications—even if we haven't called them that?

---

## Optional Reflection Fragment (Week 6, Block 6)

**Context:** You've completed both rounds of the spec test, annotated the results, and participated in a class discussion about what specification does and doesn't do.

**Task:** Write a reflection fragment (![[_def-fragment-wordcount-range]]) connecting this experience to your writing process. Consider: Where else have you been writing specifications without calling them that? Where in your current work would explicit spec-writing help you most? What did the spec test reveal about where the hard work of writing actually happens?

**Standards:** The reflection should reference at least one specific moment from the activity (a particular failure in Round 1, a specific improvement in Round 2, something a classmate said in discussion) and make at least one connection to your ongoing work in this course.

**Guidance:** This fragment is optional but valuable. You've been encountering specifications all semester—the structure on your assignment sheets, the criteria in Eli Review, the prompts that frame your daily writing. Specs are everywhere once you start looking. This reflection is a chance to name that pattern and think about what it means for how you work.

---

**Justification**: [[ai-spec-test-reasons-v101#Overview|Why this activity?]]

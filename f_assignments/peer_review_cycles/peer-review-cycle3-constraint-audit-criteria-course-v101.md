---
created: 2026-01-23
type: teaching-course-content
course: virens-101
component: f_assignments
track: content
identifier: peer-review-cycle3-constraint-audit-criteria
paired-justification: none
status: draft
tags: [teaching, virens-101, course-content, peer-review, criteria, cycle3, constraint-audit]

# === OUTCOMES ALIGNMENT ===
outcomes-addressed: [outcome-constraint-literacy, outcome-critical-thinking, outcome-rhetorical-awareness]
outcomes-primary: outcome-constraint-literacy

# === DEPENDENCY MANAGEMENT ===
sync-group: [peer-review-specs]
depends-on: [peer-review-protocol-assignment-course-v101, spec-document-constraint-audit-assignment-course-v101]
affects: []
uses-defs: []
last-sync-check: 2026-01-23
attention-flag: ""
---

# Peer Review Cycle 3: Constraint Audit Criteria

> [!info] Review Cycle Details
> **Assignment**: Constraint Audit
> **Week**: 7
> **Protocol**: Evaluative (DES - Describe, Evaluate, Suggest)
> **Draft requirement**: 60% minimum complete (480-720 words of target 800-1200)
> **Number of criteria**: 7

---

## Review Protocol: Evaluative (DES)

This cycle uses the **evaluative protocol** (Describe-Evaluate-Suggest), which provides directive, criterion-based feedback. Your reviews should assess how well the draft meets expectations and offer specific improvement strategies.

**Describe**: Identify what the writer is attempting to do  
**Evaluate**: Assess how well the draft meets the criterion  
**Suggest**: Offer specific strategies for improvement

Your feedback should be direct and actionable—help the writer understand what works, what needs development, and how to improve.

---

## Review Criteria

For each criterion below, check the box if the draft meets this standard, then write 2-4 sentences using the DES protocol. Your evaluation helps the writer understand where revision is needed.

### 1. Clear Subject for Analysis

**Check if present**: ☐ The audit identifies a specific text, process, or system to analyze and that subject is appropriate for constraint analysis

**What to assess**: Has the writer chosen something analyzable—a text they can examine closely, a process they can describe concretely, a system they can observe? Or is the subject too abstract, too broad, or not actually present?

**Evaluative response approach**:
- **Describe**: "You're auditing constraints in [subject you identify]"
- **Evaluate**: "This subject is appropriate because [reason] / This subject seems problematic because [specific issue]"
- **Suggest**: "To make this more analyzable, focus on [specific aspect]" OR "This works well—make sure you have concrete evidence from [subject]"

### 2. Multiple Constraint Types Identified

**Check if present**: ☐ The audit identifies at least three distinct constraint types (genre, resource, audience, technical, regulatory, physical, competing goals, etc.)

**What to assess**: Has the writer identified multiple, genuinely different constraint types? Or are all "constraints" really variations of one type (e.g., three time constraints but no other types)?

**Evaluative response approach**:
- **Describe**: "The constraint types I see are: [list the types you identified]"
- **Evaluate**: "These represent distinct types / These are all [single type]—you need more variety"
- **Suggest**: "Consider adding constraints related to [missing type—audience, resources, competing goals]"

### 3. Evidence-Based Analysis

**Check if present**: ☐ Claims about constraints are supported with specific examples from the text, process, or system being analyzed

**What to assess**: Does the writer provide concrete evidence (quotes from text, specific process steps, observable system features)? Or make claims without support?

**Evaluative response approach**:
- **Describe**: "Evidence appears in [where you see it] / Evidence is largely absent"
- **Evaluate**: "The evidence effectively supports claims about [constraint] / Claims about [constraint] lack specific support"
- **Suggest**: "Add specific examples showing [constraint] in action" OR "Quote/describe [specific element] to support this claim"

### 4. Constraint Interactions & Conflicts

**Check if present**: ☐ The audit examines how constraints interact, especially where they conflict or create design tensions

**What to assess**: Does the writer analyze constraint relationships—how they work together, compete, or clash? Or just list constraints without examining interactions?

**Evaluative response approach**:
- **Describe**: "You examine interaction between [constraints] / Constraints are listed separately without analyzing relationships"
- **Evaluate**: "The analysis of [constraint conflict] effectively shows how [result] / Missing analysis of how [constraint A] affects [constraint B]"
- **Suggest**: "Explore what happens when [constraint X] conflicts with [constraint Y]—how does the [text/process/system] resolve this tension?"

### 5. Use of Alexander's Framework

**Check if present**: ☐ The audit applies Alexander's concepts (goodness of fit, misfits) where appropriate to evaluate constraints

**What to assess**: Does the writer use Alexander's framework to assess where constraints are well-satisfied (goodness of fit) or create problems (misfits)? Or ignore this framework?

**Evaluative response approach**:
- **Describe**: "Alexander's framework appears in [where] / No reference to goodness of fit/misfits"
- **Evaluate**: "The misfit you identify between [constraint A] and [constraint B] effectively uses Alexander's concept / The analysis would benefit from identifying where form doesn't fit context"
- **Suggest**: "Look for misfits—where do constraints clash and create problems? Where does the [text/process/system] achieve goodness of fit despite constraints?"

### 6. Evaluative Dimension

**Check if present**: ☐ The audit assesses whether constraints are productive (enabling good outcomes) or problematic (creating barriers/inefficiencies), not just describing them neutrally

**What to assess**: Does the writer evaluate constraints' effects—what they enable, what they prevent, whether they help or harm? Or just describe constraints without judgment?

**Evaluative response approach**:
- **Describe**: "Evaluation appears when you assess [constraint] as [productive/problematic] / The audit describes constraints but doesn't evaluate them"
- **Evaluate**: "Your evaluation of [constraint] as problematic effectively shows how it [negative effect] / Need more explicit evaluation—are these constraints helping or hurting?"
- **Suggest**: "For each major constraint, assess: Does it enable good outcomes? Create unnecessary barriers? Both?"

### 7. Clear Organization & Analytical Structure

**Check if present**: ☐ The audit is organized logically so readers can follow the analysis from constraint identification through evaluation

**What to assess**: Can you follow the analytical progression? Is organization clear (by constraint type, by level of analysis, by chronology)? Or is the audit scattered or hard to follow?

**Evaluative response approach**:
- **Describe**: "Organization follows [structure you observe] / Organization is unclear—jumps between [issues]"
- **Evaluate**: "This structure works because [reason] / The structure makes it hard to follow because [specific problem]"
- **Suggest**: "Consider organizing by [principle—constraint type, severity, domain]" OR "Add transition sentences connecting [section A] to [section B]"

---

## General Guidance for Reviews

**Be direct about what needs improvement**: Evaluative protocol means honest assessment. If evidence is weak, say so and explain why. If constraints aren't actually constraints, identify the problem.

**Connect evaluation to assignment goals**: Reference the assignment sheet's standards when evaluating. The audit should identify multiple constraint types, provide evidence, analyze interactions, use Alexander, and evaluate effects.

**Offer specific revision strategies**: "Add more evidence" is less useful than "Quote specific passages from the article showing where genre conventions constrain what the author can say."

**Acknowledge what works**: Evaluative doesn't mean only critical. If constraint identification is strong, say so. If Alexander's framework is well-applied, acknowledge it. Balance helps writers know what to preserve during revision.

**Remember 60% draft status**: Expect developing analysis. Focus evaluation on whether core analytical moves are present (multiple constraint types, evidence, interaction analysis, evaluation) rather than polish.

---

## After Writing Reviews

Remember to complete your **revision plan** by Friday 11:59pm (48 hours after reviews are due):

1. Rate each review you received (1-5 stars for helpfulness)
2. Sequence your revision priorities (what to address first, second, third)
3. Write 2-3 sentences explaining your revision approach

The revision plan is worth 15 points (in addition to the 25 points for writing reviews).

---

## Related Notes

- **Assignment Sheet**: [[spec-document-constraint-audit-assignment-course-v101]]
- **Peer Review Protocol**: [[peer-review-protocol-assignment-course-v101]]
- **Alexander Reading**: [[alexander-goodness-of-fit-reading-course-v101]]
- **Eli Review Guide**: [[eli-review-student-guide-course-v101]]
- **Previous Cycle**: [[peer-review-cycle2-spec-document-criteria-course-v101]]
- **Next Cycle**: [[peer-review-cycle4-beam-source-entries-criteria-course-v101]]

---
created: 2026-01-21
type: teaching-course-justification
course: virens-101
component: c_rationale
track: justification
identifier: M2-naming-overview
paired-content: [[M2-naming-overview-course-v101]]
status: complete

# === SCHOLARLY GROUNDING ===
cites-scholars:
- Flower
- Hayes
- Alexander
- Meadows
- Schön
primary-theorist: "Alexander"

# === DEPENDENCY MANAGEMENT ===
sync-group: []
depends-on: []
affects: []
uses-defs: []
last-sync-check:
attention-flag: ""
tags: [teaching, virens-101, justification, pedagogy, c-rationale, movement-2, 
    naming]
---

# Justification: C Rationale — M2-naming-overview

> [!abstract] Pedagogical Rationale
> **Component**: C Rationale
> **Track**: Justification (why these choices)
> **Paired with**: [[M2-naming-overview-course-v101|Course Content]]
> **Status**: complete

---

## Design Philosophy

### Core Pedagogical Principle

Movement 2 operationalizes **source integration as structured practice** and **constraint visibility as rhetorical knowledge**. Where M1 emphasized generation without classification, M2 introduces taxonomies (BEAM), procedures (SEAR), and organizational systems that make implicit writing work explicit.

The design recognizes that novice writers struggle with sources not because they can't paraphrase or cite correctly, but because they don't understand *what sources do* in academic writing. BEAM reframes citation as functional rather than mechanical: sources are tools with different uses, not just requirements to fulfill. Similarly, the Constraint Audit makes rhetorical analysis concrete by focusing on visible forces that shape texts.

M2's balanced W-P-R rhythm (writing, peer review, revision cycling together) establishes the feedback loop as normal part of composing, not exceptional event. Students write *anticipating* feedback and revise *using* feedback, integrating critique into process rather than treating it as judgment after completion.

### Theoretical Grounding

**Citation as Dependency Management** (course-specific innovation): M2 introduces citations not as formatting exercises but as *links in a knowledge graph*. This framing comes from software engineering's dependency management—your argument depends on source claims, your evidence depends on source data. If sources change or disappear, what breaks in your argument?

**BEAM Taxonomy** (Bizup): Joseph Bizup's BEAM framework provides *functional* categories for source use, answering "what does this source *do* in my writing?" rather than "what type of source is this?" This shift from bibliographic categories (scholarly vs. popular, primary vs. secondary) to functional categories makes source choice strategic rather than prescriptive.

**Constraint Sequencing** (Alexander [[@alexander1964notet]], Schön, Meadows [[@meadows2008lever]]): M2 makes explicit the course's commitment to *when* constraints arrive, not just *what* they are. Students experience constraint-free generation (M1), then deliberate addition of constraints (M2 Zotero + feedback + specs), observing how each constraint changes their process and products. This sequence inverts traditional teaching that frontloads all requirements at once.

**Key Sources:**
- Bizup, Joseph. "BEAM: A Rhetorical Vocabulary for Teaching Research-Based Writing." *Rhetoric Review* 27.1 (2008): 72-86.
- Howard, Rebecca Moore, et al. "Writing from Sources, Writing from Sentences." *Writing & Pedagogy* 2.2 (2010): 177-92.
- Alexander, Christopher. *Notes on the Synthesis of Form*. Harvard UP, 1964. [On problem decomposition and misfits]

**Concepts Applied:**
- Sources as functional tools, not just authorities to cite
- Taxonomies that classify by *use* rather than *type*
- Constraint arrival timing as pedagogical variable
- Feedback cycles integrated into composing (not external to it)
- Making invisible work visible (dev logs, specs, constraint audits)

---

## Learning Objectives

### Why These Objectives?

Movement 2 objectives target **procedural knowledge**—how to *do* things with sources, systems, and feedback—rather than declarative knowledge (facts about writing). Students learn *operations*: classify sources, route material, engage peer feedback, specify constraints. These are transferable skills applicable beyond this course.

The objectives also emphasize **metacognitive awareness**: noticing *how* constraints shape writing, observing *how* feedback changes drafts, recognizing *how* classification enables finding. This meta-level understanding supports transfer—students can adapt procedures to new contexts because they understand the principles.

### Scaffolding Logic

**Builds on:** M1 generated raw material without classification. Students have 8-12 fragments but limited systems for organizing them. M2 teaches the organizational and source-engagement work that's now necessary because students *have* material to organize and sources to engage.

**Prepares for:** M3 requires corpus-level operations (consolidation, connection, refactoring) that depend on classification systems. Without M2's BEAM tagging and folder routing, students would be overwhelmed by scale. M4's portfolio assembly depends on being able to *find* related fragments quickly—M2's classification makes that possible.

**Constraint Sequencing Principle**: M2 adds constraints deliberately and visibly:
- **Week 4**: Source engagement constraint (write *with* readings, not just from experience)
- **Week 5**: Citation constraint (use Zotero, format correctly)
- **Week 5-7**: Feedback constraint (write for peer review, incorporate comments)
- **Week 6-7**: Specification constraint (articulate intentions before drafting)

Each constraint arrives when prior work makes it necessary or meaningful. Students see *why* they need citation management (lots of sources to track) and *why* spec documents help (complex projects benefit from pre-drafting clarity).

---

## Pedagogical Approach

### Activity Design Rationale

**Zotero Library Session** (Week 5, T3-T4): The timing is strategic—*after* students have already written with sources informally (Week 4). This creates a "before-after" contrast: students experience the difference between ad-hoc citation and tool-supported citation management. If Zotero arrived Week 1, students wouldn't appreciate its value.

**Pedagogical foundation**: "Just-in-time" learning (students learn tools when they need them) and threshold concept theory (tool introduction follows need recognition, not precedes it).

**Spec Documents**: Borrowed from software development but adapted for composition. Developers write specs before coding; students write specs before drafting major projects. The assignment makes *intention* explicit and *negotiable*—students articulate what they're trying to accomplish, then can revise that intention rather than feeling locked in.

**Pedagogical foundation**: Pre-writing as discovery (Flower [[@flower1981cogni]] & Hayes), but structured differently. Instead of brainstorming or freewriting, students specify constraints, scope, and success criteria. This is *analytical* pre-writing rather than *generative* pre-writing.

**Constraint Audit**: Rhetorical analysis reframed as constraint analysis. Traditional rhetorical analysis asks "how does this text persuade?" Constraint audit asks "what forces shaped this text?" The shift from *effectiveness* to *causality* makes analysis more accessible to students who struggle with evaluative judgment.

**Pedagogical foundation**: Systems thinking (Meadows—identifying forces that shape system behavior) and design theory (Alexander—identifying misfits and constraints in design problems). Also informed by genre theory (Devitt, Bawarshi)—genres are patterns of constraints that have stabilized over time.

### Time Allocation Logic

**Balanced W-P-R pattern**: Movement 2 shifts from M1's W-W-W-W-W-W pattern to a cycling W-P-R rhythm. This reflects the integration of feedback into composing process:

- **W blocks**: Generate new material, develop drafts
- **P blocks**: Give peer feedback (Eli Review), practice substantive commenting
- **R blocks**: Process feedback, make revision plans, implement changes

This pattern teaches that *writing includes feedback cycles*, not just individual production. Students learn to anticipate revision (write *for* feedback) and use critique productively (feedback informs next drafts).

**Why balanced?** Research on peer review effectiveness (Topping, Cho & Schunn) suggests that *both* giving and receiving feedback support learning. Students learn to evaluate writing by evaluating peers' writing. Balancing W-P-R ensures students spend significant time in all three modes, not just producing text (W-only) or revising (R-only).

### Differentiation Strategies

**For students who struggle with peer feedback**:
- Provide sentence stems: "The strongest part of this draft is... because..." / "One place that needs more development is... because..."
- Model useful vs. not-useful feedback in class
- Emphasize that critique isn't personal—it's about helping the *writing* get better

**For students who resist formal citation**:
- Frame Zotero as labor-saving (it formats for you) not labor-adding (one more thing to learn)
- Demonstrate that citation enables tracing—following links to find related sources
- Connect to attribution ethics (giving credit) and academic integrity (avoiding plagiarism) pragmatically

**For advanced students who feel constrained by structure**:
- Explain that constraints are *variables* they'll learn to adjust, not fixed rules
- Invite experimentation: "What happens if you break this constraint deliberately?"
- Frame structure as scaffolding that can be removed once internalized

---

## Assignment Design

### Spec Document + Constraint Audit (Combined)

**Why these assignments specifically?**

The Spec Document and Constraint Audit form a complementary pair: one is *forward-looking* (planning writing before doing it), the other is *backward-looking* (analyzing constraints that shaped completed writing). Together they develop **constraint literacy**—the ability to recognize, articulate, and manipulate the forces that shape writing.

These assignments substitute for traditional "rhetorical analysis" essays, which often devolve into formulaic identification of rhetorical appeals (ethos, pathos, logos). By focusing on *constraints* rather than *persuasiveness*, students analyze forces that operate on writers, not just effects produced in readers. This is more accessible to novice writers and more directly transferable.

### Prompt Design

**Spec Document constraints**:

| Constraint | Pedagogical Purpose |
|------------|-------------------|
| "Before drafting the project" | Separates planning from execution; makes intention explicit |
| "Purpose, Audience, Constraints, Success Criteria" | Structured template reduces decision paralysis |
| "500-800 words" | Substantial enough to be useful, not so long it becomes busywork |
| "Revisable document" | Specs can change as project evolves—not locked in |

**Constraint Audit constraints**:

| Constraint | Pedagogical Purpose |
|------------|-------------------|
| "Explicit and implicit constraints" | Surfaces unstated rules alongside stated ones |
| "How text would change if constraints changed" | Makes constraint effects visible through counterfactual |
| "Annotated example" | Anchors analysis in concrete textual evidence |
| "800-1000 words" | Requires substantive analysis, not just listing |

### Anticipated Student Interpretations

**Possible misreading (Spec Doc)**: "I need to stick exactly to what I specify and can't deviate."  
**Mitigation**: Emphasize that specs are *working documents*—they guide but don't lock you in. If you discover something better while drafting, you revise the spec, not force the writing to match.

**Possible misreading (Constraint Audit)**: "I need to identify every possible constraint."  
**Mitigation**: Frame as *selective* analysis—choose the most significant constraints, the ones that most visibly shaped the text. Completeness isn't the goal; insight is.

**Possible misreading (both)**: "These assignments are about 'rules' of writing."  
**Mitigation**: Constraints aren't rules—they're variables. Rules are fixed; constraints can be adjusted, sequenced, negotiated. Learning constraint literacy means learning *when* to follow, *when* to bend, and *when* to break.

---

## Assessment Criteria

### Rubric Philosophy

M2 assignments value **analytical insight** over compliance. Students demonstrate understanding by identifying non-obvious constraints, explaining why they matter, and articulating how changes would cascade. This is *application* and *analysis* level (Bloom's taxonomy), not just knowledge or comprehension.

The rubric rewards **specificity**: concrete examples, pointed analysis, clear cause-effect reasoning. Vague generalizations ("constraints shape writing") receive lower marks than precise observations ("the 800-word limit forced me to cut examples, which weakened my evidence but made my argument clearer").

### Criterion Weighting

**Spec Document** (25 points of 50 total for M2 milestone):

| Criterion | Weight | Justification |
|-----------|--------|---------------|
| Clarity of purpose and audience | 30% | Foundation for all other choices |
| Specificity of constraints and scope | 30% | Shows understanding that boundaries enable focus |
| Feasibility of success criteria | 20% | Criteria must be achievable and observable |
| Usefulness as planning tool | 20% | Would this actually guide drafting? |

**Constraint Audit** (25 points of 50 total for M2 milestone):

| Criterion | Weight | Justification |
|-----------|--------|---------------|
| Identification of non-obvious constraints | 30% | Depth of analysis, not just surface features |
| Explanation of how constraints shaped text | 30% | Causal reasoning, not just description |
| Counterfactual analysis (how text would change) | 25% | Demonstrates understanding of constraint effects |
| Textual evidence and specificity | 15% | Concrete examples anchor analysis |

### Formative vs. Summative

M2 milestones are **more summative than M1** but still developmentally oriented. Students receive grades that matter (50 points), but assignments can be revised for portfolio inclusion (M4), where they're assessed again under higher standards. This staged assessment allows students to demonstrate growth: what counts as "good" work in Week 7 might be "adequate" work by Week 15 after revision.

**Assessment sequence** across movements:
- **M1**: Primarily formative (completion + engagement)
- **M2**: Mixed formative-summative (graded on analysis quality, revisable)
- **M3**: Increasingly summative (corpus-level work graded more rigorously)
- **M4**: Fully summative (final portfolio judged on culminating standards)

---

## Source Engagement: BEAM & SEAR

### Why BEAM?

Traditional source instruction focuses on *types* (primary/secondary, scholarly/popular) or *formats* (book/article/website). BEAM reframes by *function*: What does this source *do* in your argument?

**Pedagogical advantage**: Functional categories are more useful for decision-making. If students know they need "background," they know to look for definitional or contextual sources. If they know they need "exhibit," they look for examples or data to analyze. Functional thinking is strategic thinking.

**Research support**: Bizup's original article (2008) and subsequent implementations show that BEAM helps students make purposeful source choices rather than just "find three sources." It also helps students *use* sources differently—not every source needs to be an authority whose claims you accept (Argument sources); some are just context (Background) or material to analyze (Exhibit).

### Why SEAR?

SEAR (Situate, Embed, Analyze, Relate) addresses common novice writer problems with source integration:
- "Drive-by quotation" (quote without analysis)
- "Hanging quotation" (quote disconnected from surrounding text)
- "Quote spam" (excessive quotation without synthesis)

**Pedagogical advantage**: SEAR provides a *procedure*—a sequence of operations students can follow. Instead of vague advice like "integrate sources smoothly," students get concrete steps:

1. **Situate**: Give readers context for the source (who, when, why it matters)
2. **Embed**: Quote or paraphrase the specific passage
3. **Analyze**: Explain what the passage means, what's significant about it
4. **Relate**: Connect it to your claim/argument

This procedural knowledge is more actionable than abstract principles. Students can *check* whether they've done all four steps, making revision concrete.

---

## Peer Review Integration: Eli Review

### Pedagogical Justification

**Why structured peer review platform?** Research on peer review effectiveness (Cho, Schunn, & Wilson 2006; Nilson 2003) shows that peer review improves writing quality *when* it's structured, reciprocal, and tied to revision. Unstructured peer review (e.g., "exchange papers with a partner and give comments") often produces vague, unhelpful feedback.

Eli Review structures the process:
- **Guided prompts**: Students answer specific questions about the draft, not just "what did you think?"
- **Anonymization**: Reduces personal awkwardness; students focus on the *writing*, not the *writer*
- **Helpfulness ratings**: Students rate feedback quality, enabling better matching over time
- **Revision planning**: Feedback culminates in actionable revision plan, not just comments received

**Timing strategy**: M2 introduces *graded* Eli cycles after M1's ungraded familiarization. Students have touched the system (Week 2), understand the interface, and can now focus on the *quality* of feedback, not just the mechanics of the system.

### Integration with W-P-R Rhythm

Eli Review makes the feedback cycle *structural* rather than *optional*:
- **W blocks**: Draft knowing you'll receive feedback
- **P blocks**: Give feedback to peers (learning to evaluate writing)
- **R blocks**: Process feedback, plan revisions, implement changes

This integration normalizes critique as part of writing, not punishment for failure. Students learn that *all* writers benefit from feedback, and that giving feedback (evaluating others' writing) improves your own writing by developing evaluative judgment.

---

## Evidence & Iteration

### Evidence to Collect

- [ ] Fragment count per student at Week 7 checkpoint (target: 20-28)
- [ ] Zotero library size (number of sources added, tagged)
- [ ] BEAM tagging accuracy (do students classify sources appropriately?)
- [ ] Peer feedback quality (Eli Review helpfulness ratings—do they improve over time?)
- [ ] Dev log entries (frequency, substance, evidence of reflection)
- [ ] Spec Document usefulness (student self-reports—did it actually guide their work?)
- [ ] Constraint Audit depth (how many non-obvious constraints identified?)

### Revision Notes

**From prior iterations** (if applicable):
- Students sometimes confuse BEAM categories initially—particularly Background vs. Method. May need additional examples showing how same source can be multiple BEAM types depending on use.
- Spec Documents sometimes become too vague ("write a good essay about literacy"). Need to push for concrete success criteria ("readers should be able to identify three specific turning points in my literacy development").
- Constraint Audits sometimes list constraints without analyzing their effects. Need to emphasize the *causal* component: not just "what constraints existed" but "how they shaped the text."

**For future iterations**:
- Consider adding a "constraint experiment" mini-assignment: write the same fragment under three different constraint sets, observe what changes.
- Experiment with peer Spec Document review *before* drafting—students give feedback on each other's specs, helping clarify intentions.
- Develop more robust SEAR scaffolds—worksheets, sentence stems, models of exemplary source integration.

---

## Scholarly Sources

### Direct Citations

**Source Engagement**:
- Bizup, Joseph. "BEAM: A Rhetorical Vocabulary for Teaching Research-Based Writing." *Rhetoric Review* 27.1 (2008): 72-86.
- Howard, Rebecca Moore, et al. "Writing from Sources, Writing from Sentences." *Writing & Pedagogy* 2.2 (2010): 177-92.
- Harris [[@harris1997teach]], Joseph. *Rewriting: How to Do Things with Texts*. Utah State UP, 2006.

**Peer Review & Feedback**:
- Cho, Kwangsu, and Christian D. Schunn. "Scaffolded Writing and Rewriting in the Discipline: A Web-Based Reciprocal Peer Review System." *Computers & Education* 48.3 (2007): 409-26.
- Nilson, Linda B. "Improving Student Peer Feedback." *College Teaching* 51.1 (2003): 34-38.
- Topping, Keith. "Peer Assessment Between Students in Colleges and Universities." *Review of Educational Research* 68.3 (1998): 249-76.

**Constraints & Design**:
- Alexander, Christopher. *Notes on the Synthesis of Form*. Harvard UP, 1964.
- Schön, Donald. *The Reflective Practitioner: How Professionals Think in Action*. Basic Books, 1983.
- Meadows, Donella. *Thinking in Systems: A Primer*. Chelsea Green, 2008.

### Background Reading

**On genre and constraints**:
- Devitt, Amy J. "Teaching Critical Genre Awareness." *Genre in a Changing World* (2009): 337-51.
- Bawarshi, Anis S., and Mary Jo Reiff. *Genre: An Introduction to History, Theory, Research, and Pedagogy*. Parlor Press, 2010.

**On source integration**:
- Jamieson, Sandra. "Reading and Engaging Sources: What Students' Use of Sources Reveals about Advanced Reading Skills." *Across the Disciplines* 10.4 (2013).
- Sullivan, Patrick. "'Deep Reading' as a Threshold Concept in Composition Studies." *The CEA Forum* 46.2 (2017): 32-50.

---

## Related Justifications

```dataview
TABLE component, identifier, status
FROM "600_teaching/virens_101"
WHERE type = "teaching-course-justification"
  AND file.name != this.file.name
  AND (contains(identifier, "M2") 
       OR contains(component, "c_rationale"))
SORT component ASC, identifier ASC
```

---

## Paired Content

**See**: [[M2-naming-overview-course-v101]]

---

*Created: 2026-01-21*
*Component: C Rationale*
*Course: VIRENS 101*